--- tests/test_validation.py
+++ tests/test_validation.py
@@ -26,50 +26,93 @@ def sample_acs_data() -> pd.DataFrame:
     return pd.DataFrame({
         "name": ["New York, NY", "Los Angeles, CA", "Chicago, IL"],
         "b19013_001e": [75000, 65000, 55000],  # Median household income
         "b01003_001e": [8500000, 4000000, 2700000],  # Population
         "data_year": [2022, 2022, 2022],
         "source": ["census_api", "census_api", "census_api"],
         "ingested_at": pd.Timestamp.now(),
         "as_of": "2025-01"
     })


 @pytest.fixture
 def sample_market_data() -> pd.DataFrame:
     """Create sample market scoring data for testing."""
     return pd.DataFrame({
         "name": ["New York, NY", "Los Angeles, CA", "Chicago, IL"],
         "market_score": [85.5, 78.2, 72.1],
         "market_tier": ["A", "B", "B"],
         "scoring_model": ["simple_income_population_v1"] * 3,
         "scored_at": pd.Timestamp.now(),
         "data_year": [2022, 2022, 2022],
         "source": ["data_lake", "data_lake", "data_lake"]
     })


+@pytest.fixture
+def sample_market_analytics() -> pd.DataFrame:
+    return pd.DataFrame(
+        {
+            "msa_id": ["123456789012"],
+            "market_name": ["Test Market"],
+            "population": [100000],
+            "households": [40000],
+            "vacancy_rate": [5.0],
+            "permit_per_1k": [2.5],
+            "tech_cagr": [4.0],
+            "walk_15_ct": [25],
+            "trail_mi_pc": [1.5],
+            "supply_score": [4.0],
+            "jobs_score": [3.5],
+            "urban_score": [3.0],
+            "outdoor_score": [2.5],
+            "composite_score": [3.5],
+            "period_month": [pd.Timestamp("2025-09-01")],
+            "refreshed_at": [pd.Timestamp.now()],
+            "run_id": [1],
+        }
+    )
+
+
+@pytest.fixture
+def sample_asset_performance() -> pd.DataFrame:
+    return pd.DataFrame(
+        {
+            "asset_id": [1],
+            "msa_id": ["123456789012"],
+            "units": [120],
+            "year_built": [2010],
+            "score": [75.0],
+            "market_composite_score": [70.0],
+            "rank_in_market": [1],
+            "period_month": [pd.Timestamp("2025-09-01")],
+            "refreshed_at": [pd.Timestamp.now()],
+            "run_id": [1],
+        }
+    )
+
+
 @pytest.fixture
 def invalid_acs_data() -> pd.DataFrame:
     """Create invalid ACS data for testing validation failures."""
     return pd.DataFrame({
         "name": ["New York, NY", None, "Chicago, IL"],  # Missing name
         "b19013_001e": [75000, -1000, 55000],  # Negative income
         "b01003_001e": [8500000, 65000, 2700000],
         "data_year": [2022, 2022, 2035],  # Invalid year
         "source": ["invalid_source", "census_api", "census_api"],
         "ingested_at": pd.Timestamp.now(),
         "as_of": "2025-01"
     })


 class TestValidationResult:
     """Test ValidationResult class."""

     def test_validation_result_success(self) -> None:
         """Test ValidationResult with successful validation."""
         mock_results = [MagicMock()]
         mock_results[0].success = True
         mock_results[0].results = []

         result = ValidationResult(True, mock_results)

@@ -204,50 +247,102 @@ class TestPrefectTasks:
             mock_validator_class.return_value = mock_validator

             with pytest.raises(ValueError, match="Data validation failed"):
                 validate_data_quality(
                     df=sample_acs_data,
                     suite_name="test_suite",
                     fail_on_error=True
                 )

     def test_validate_data_quality_task_no_fail(self, sample_acs_data: pd.DataFrame) -> None:
         """Test validate_data_quality task without failing on errors."""
         with patch("aker_core.validation.GreatExpectationsValidator") as mock_validator_class:
             mock_validator = MagicMock()
             mock_validator.validate_dataframe.return_value = ValidationResult(False, [])
             mock_validator_class.return_value = mock_validator

             result = validate_data_quality(
                 df=sample_acs_data,
                 suite_name="test_suite",
                 fail_on_error=False
             )

             assert result["success"] is False


+class TestDatasetValidationRouting:
+    def test_validate_dataset_market_analytics(self, monkeypatch, sample_market_analytics) -> None:
+        captured: dict[str, str] = {}
+
+        class DummyValidator:
+            def __init__(self, run_context=None):
+                self.context = MagicMock()
+                self.context.get_expectation_suite.side_effect = Exception()
+
+            def create_suite_from_yaml(self, yaml_path: str, suite_name: str) -> str:
+                captured["yaml"] = yaml_path
+                captured["suite"] = suite_name
+                return suite_name
+
+            def validate_dataframe(self, df: pd.DataFrame, suite_name: str) -> ValidationResult:
+                captured["validate_suite"] = suite_name
+                return ValidationResult(True, [])
+
+        monkeypatch.setattr("aker_core.validation.GreatExpectationsValidator", DummyValidator)
+
+        result = validate_dataset(sample_market_analytics, "market_analytics")
+        assert result.success is True
+        assert captured["suite"] == "market_analytics_validation"
+        assert captured["validate_suite"] == "market_analytics_validation"
+        assert captured["yaml"].endswith("market_analytics.yml")
+
+    def test_validate_dataset_asset_performance(self, monkeypatch, sample_asset_performance) -> None:
+        captured: dict[str, str] = {}
+
+        class DummyValidator:
+            def __init__(self, run_context=None):
+                self.context = MagicMock()
+                self.context.get_expectation_suite.side_effect = Exception()
+
+            def create_suite_from_yaml(self, yaml_path: str, suite_name: str) -> str:
+                captured["yaml"] = yaml_path
+                captured["suite"] = suite_name
+                return suite_name
+
+            def validate_dataframe(self, df: pd.DataFrame, suite_name: str) -> ValidationResult:
+                captured["validate_suite"] = suite_name
+                return ValidationResult(True, [])
+
+        monkeypatch.setattr("aker_core.validation.GreatExpectationsValidator", DummyValidator)
+
+        result = validate_dataset(sample_asset_performance, "asset_performance")
+        assert result.success is True
+        assert captured["suite"] == "asset_performance_validation"
+        assert captured["validate_suite"] == "asset_performance_validation"
+        assert captured["yaml"].endswith("asset_performance.yml")
+
+
 class TestDatasetValidation:
     """Test dataset validation functionality."""

     def test_validate_dataset_mapping(self, sample_acs_data: pd.DataFrame) -> None:
         """Test dataset type to suite mapping."""
         with patch("aker_core.validation.GreatExpectationsValidator") as mock_validator_class:
             mock_validator = MagicMock()
             mock_validator.validate_dataframe.return_value = ValidationResult(True, [])
             mock_validator_class.return_value = mock_validator

             # Test ACS dataset
             result = validate_dataset(sample_acs_data, "acs")
             assert result.success is True

             # Test market data
             result = validate_dataset(sample_acs_data, "market_data")
             assert result.success is True

     def test_validate_dataset_invalid_type(self) -> None:
         """Test validation with invalid dataset type."""
         with pytest.raises(ValueError, match="No validation suite found"):
             validate_dataset(pd.DataFrame(), "invalid_type")


 class TestQualityGateScript:
